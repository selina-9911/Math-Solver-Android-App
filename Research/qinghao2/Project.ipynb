{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "loving-austin",
   "metadata": {},
   "source": [
    "Resources for project:\n",
    "\n",
    "Sprint 2\n",
    "* https://docs.google.com/document/d/1844qzQOHay-M4oYFzK9LScxbnZGResRUWGwPO0qvZwQ/edit\n",
    "\n",
    "Sprint 3:\n",
    "* look over tutorial for easy image classification using tensorflow: https://towardsdatascience.com/easy-image-classification-with-tensorflow-2-0-f734fee52d13\n",
    "* For the following dataset: https://www.kaggle.com/clarencezhao/handwritten-math-symbol-dataset\n",
    "\n",
    "  Preprocessing:\n",
    "\n",
    "*  explore the dataset - look around at organization of directories\n",
    "*  import np, pd, plt, keras\n",
    " * load paths for training and testing images\n",
    "*  split the data into appropriate training and testing image sets (x_train, x_test, y_train, y_test)\n",
    "  Models:\n",
    "\n",
    "*  reading on functional models: https://medium.com/@antika.das/keras-models-cnn-functional-vs-sequential-mnist-data-set-d7a19dae9cb7\n",
    "*  begin attempting a sequential model for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "monthly-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action = 'ignore', category = FutureWarning)\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-michigan",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "#organize data into train and test batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "prescribed-state",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7557 images belonging to 16 classes.\n",
      "Found 1010 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function = tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory='dataset/train',target_size = (224,224),classes = ['decimal','div','eight','equal','five','four','minus','nine','one','plus cleaned','seven','six','three','times','two','zero'],batch_size = 10)\n",
    "test_batches = ImageDataGenerator(preprocessing_function = tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory='dataset/eval',target_size = (224,224),classes = ['decimal val','div val','eight','equal val','five','four','minus val','nine','one', 'plus val','seven','six','three','times val','two','zero'],batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "front-failure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7557\n"
     ]
    }
   ],
   "source": [
    "print(train_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cleared-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs,train_labels = next(train_batches) #10images and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "crazy-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs,test_labels = next(train_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-adobe",
   "metadata": {},
   "source": [
    "## Build and Train a sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "spatial-laptop",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters = 32,kernel_size = (3,3),activation = 'relu',padding='same',input_shape=(224,224,3)),\n",
    "    MaxPool2D(pool_size=(2,2),strides = 2),\n",
    "    Conv2D(filters = 64,kernel_size = (3,3),activation = 'relu',padding = 'same'),\n",
    "    MaxPool2D(pool_size=(2,2),strides = 2),\n",
    "    Flatten(),\n",
    "    Dense(units=16,activation = 'softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dominican-metadata",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 112, 112, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 200704)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                3211280   \n",
      "=================================================================\n",
      "Total params: 3,230,672\n",
      "Trainable params: 3,230,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "sized-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = Adam(learning_rate=0.0001),loss = 'categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "leading-snapshot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 756 steps, validate for 101 steps\n",
      "Epoch 1/10\n",
      "756/756 - 208s - loss: 26.7188 - accuracy: 0.5407 - val_loss: 0.8458 - val_accuracy: 0.7406\n",
      "Epoch 2/10\n",
      "756/756 - 231s - loss: 0.1836 - accuracy: 0.9460 - val_loss: 0.8661 - val_accuracy: 0.7782\n",
      "Epoch 3/10\n",
      "756/756 - 236s - loss: 0.0273 - accuracy: 0.9958 - val_loss: 0.9182 - val_accuracy: 0.8030\n",
      "Epoch 4/10\n",
      "756/756 - 244s - loss: 0.0097 - accuracy: 0.9988 - val_loss: 0.9440 - val_accuracy: 0.8000\n",
      "Epoch 5/10\n",
      "756/756 - 272s - loss: 0.0209 - accuracy: 0.9951 - val_loss: 1.0002 - val_accuracy: 0.7950\n",
      "Epoch 6/10\n",
      "756/756 - 217s - loss: 0.0724 - accuracy: 0.9803 - val_loss: 1.3887 - val_accuracy: 0.7178\n",
      "Epoch 7/10\n",
      "756/756 - 204s - loss: 0.0641 - accuracy: 0.9800 - val_loss: 1.0486 - val_accuracy: 0.7703\n",
      "Epoch 8/10\n",
      "756/756 - 208s - loss: 0.0138 - accuracy: 0.9971 - val_loss: 1.2090 - val_accuracy: 0.7802\n",
      "Epoch 9/10\n",
      "756/756 - 202s - loss: 0.0115 - accuracy: 0.9971 - val_loss: 1.2125 - val_accuracy: 0.7921\n",
      "Epoch 10/10\n",
      "756/756 - 238s - loss: 0.0073 - accuracy: 0.9984 - val_loss: 1.2471 - val_accuracy: 0.7921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x152ed7410>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_batches,validation_data = test_batches,epochs = 10,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
